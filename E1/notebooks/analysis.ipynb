{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Compression Analysis Notebook\n",
    "\n",
    "This notebook provides an interactive environment for analyzing compression experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import project modules\n",
    "from src.models.predictive_masking import PredictiveMaskingCompressor\n",
    "from src.models.latent_space_quantization import LatentSpaceQuantizationCompressor\n",
    "from src.evaluation.metrics import CompressionMetrics\n",
    "from src.visualization.plots import CompressionVisualizer\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most recent results\n",
    "results_dir = Path('../results/results')\n",
    "result_files = list(results_dir.glob('results_*.json'))\n",
    "\n",
    "if result_files:\n",
    "    latest_results = sorted(result_files)[-1]\n",
    "    print(f\"Loading results from: {latest_results}\")\n",
    "    \n",
    "    with open(latest_results, 'r') as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    print(\"No results found. Please run experiments first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "\n",
    "for model_method, model_results in results.items():\n",
    "    for prob, metrics in model_results.items():\n",
    "        if isinstance(prob, str) and prob.replace('.', '').isdigit():\n",
    "            prob = float(prob)\n",
    "            summary_data.append({\n",
    "                'Model': model_method.split('_')[0],\n",
    "                'Method': 'Predictive Masking' if 'predictive' in model_method else 'LSQ',\n",
    "                'Masking Probability': prob,\n",
    "                'Compression Ratio': metrics.get('compression_ratio', 0),\n",
    "                'Word Accuracy': metrics.get('word_accuracy', 0),\n",
    "                'Semantic Similarity': metrics.get('semantic_similarity', 0),\n",
    "                'ROUGE-1 F1': metrics.get('rouge1_fmeasure', 0),\n",
    "                'BERT Score F1': metrics.get('bert_score_f1', 0)\n",
    "            })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "df_summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Configurations Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configurations for each model\n",
    "best_configs = []\n",
    "\n",
    "for model in df_summary['Model'].unique():\n",
    "    for method in df_summary['Method'].unique():\n",
    "        model_data = df_summary[(df_summary['Model'] == model) & (df_summary['Method'] == method)]\n",
    "        \n",
    "        if len(model_data) > 0:\n",
    "            # Best compression ratio with acceptable quality (semantic similarity > 0.8)\n",
    "            quality_data = model_data[model_data['Semantic Similarity'] > 0.8]\n",
    "            if len(quality_data) > 0:\n",
    "                best_idx = quality_data['Compression Ratio'].idxmax()\n",
    "                best_configs.append(quality_data.loc[best_idx])\n",
    "\n",
    "best_df = pd.DataFrame(best_configs)\n",
    "print(\"Best Configurations (Semantic Similarity > 0.8):\")\n",
    "best_df.sort_values('Compression Ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Compression Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive compression demo\n",
    "def compress_and_display(text, model_name='bert-base-uncased', masking_prob=0.5):\n",
    "    \"\"\"Compress text and display results.\"\"\"\n",
    "    \n",
    "    # Initialize compressor\n",
    "    compressor = PredictiveMaskingCompressor(model_name)\n",
    "    \n",
    "    # Compress\n",
    "    compressed = compressor.compress(text, masking_probability=masking_prob)\n",
    "    \n",
    "    # Decompress\n",
    "    reconstructed = compressor.decompress(compressed)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics_calc = CompressionMetrics()\n",
    "    metrics = metrics_calc.calculate_all_metrics(text, reconstructed, compressed)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Masking Probability: {masking_prob}\")\n",
    "    print(f\"\\nOriginal Text ({len(text)} chars):\")\n",
    "    print(text)\n",
    "    print(f\"\\nReconstructed Text ({len(reconstructed)} chars):\")\n",
    "    print(reconstructed)\n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  - Compression Ratio: {metrics['compression_ratio']:.2f}\")\n",
    "    print(f\"  - Word Accuracy: {metrics['word_accuracy']:.3f}\")\n",
    "    print(f\"  - Semantic Similarity: {metrics['semantic_similarity']:.3f}\")\n",
    "    print(f\"  - ROUGE-1 F1: {metrics['rouge1_fmeasure']:.3f}\")\n",
    "    \n",
    "    return compressed, reconstructed, metrics\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"\"\"The compression of natural language text using neural networks represents \n",
    "a fascinating intersection of information theory and deep learning. By leveraging the \n",
    "predictive capabilities of transformer models, we can achieve significant compression \n",
    "ratios while maintaining semantic coherence.\"\"\"\n",
    "\n",
    "compressed, reconstructed, metrics = compress_and_display(sample_text, masking_prob=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression Trade-off Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze compression vs quality trade-off\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Compression Ratio vs Semantic Similarity\n",
    "for model in df_summary['Model'].unique():\n",
    "    model_data = df_summary[df_summary['Model'] == model]\n",
    "    pm_data = model_data[model_data['Method'] == 'Predictive Masking']\n",
    "    \n",
    "    if len(pm_data) > 0:\n",
    "        axes[0].plot(pm_data['Compression Ratio'], \n",
    "                    pm_data['Semantic Similarity'],\n",
    "                    marker='o', label=model, linewidth=2)\n",
    "\n",
    "axes[0].set_xlabel('Compression Ratio')\n",
    "axes[0].set_ylabel('Semantic Similarity')\n",
    "axes[0].set_title('Compression vs Semantic Preservation')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Masking Probability vs Multiple Metrics\n",
    "model_data = df_summary[df_summary['Model'] == 'bert-base-uncased']\n",
    "pm_data = model_data[model_data['Method'] == 'Predictive Masking'].sort_values('Masking Probability')\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2_twin = ax2.twinx()\n",
    "\n",
    "ax2.plot(pm_data['Masking Probability'], pm_data['Compression Ratio'], \n",
    "         'b-', marker='o', label='Compression Ratio')\n",
    "ax2_twin.plot(pm_data['Masking Probability'], pm_data['Semantic Similarity'], \n",
    "             'r-', marker='s', label='Semantic Similarity')\n",
    "\n",
    "ax2.set_xlabel('Masking Probability')\n",
    "ax2.set_ylabel('Compression Ratio', color='b')\n",
    "ax2_twin.set_ylabel('Semantic Similarity', color='r')\n",
    "ax2.set_title('BERT: Masking Probability Effects')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "ax2_twin.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Add legends\n",
    "lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2_twin.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison of models\n",
    "from scipy import stats\n",
    "\n",
    "# Compare models at 50% masking probability\n",
    "mask_prob = 0.5\n",
    "comparison_data = df_summary[(df_summary['Masking Probability'] == mask_prob) & \n",
    "                            (df_summary['Method'] == 'Predictive Masking')]\n",
    "\n",
    "print(f\"Model Comparison at {mask_prob:.0%} Masking Probability:\\n\")\n",
    "print(comparison_data[['Model', 'Compression Ratio', 'Word Accuracy', \n",
    "                      'Semantic Similarity', 'ROUGE-1 F1']].to_string(index=False))\n",
    "\n",
    "# Calculate correlations\n",
    "print(\"\\n\\nCorrelation Analysis:\")\n",
    "correlation_cols = ['Masking Probability', 'Compression Ratio', \n",
    "                   'Word Accuracy', 'Semantic Similarity', 'ROUGE-1 F1']\n",
    "correlations = df_summary[correlation_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlations, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Metric Correlations')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LaTeX table for paper\n",
    "latex_data = []\n",
    "\n",
    "for model in ['bert-base-uncased', 'roberta-base', 'distilbert-base-uncased']:\n",
    "    for prob in [0.3, 0.5, 0.7]:\n",
    "        row_data = df_summary[(df_summary['Model'] == model) & \n",
    "                             (df_summary['Masking Probability'] == prob) &\n",
    "                             (df_summary['Method'] == 'Predictive Masking')]\n",
    "        \n",
    "        if len(row_data) > 0:\n",
    "            row = row_data.iloc[0]\n",
    "            latex_data.append({\n",
    "                'Model': model.split('-')[0].upper(),\n",
    "                'Masking': f\"{prob:.0%}\",\n",
    "                'Compression': f\"{row['Compression Ratio']:.2f}\",\n",
    "                'Word Acc.': f\"{row['Word Accuracy']:.3f}\",\n",
    "                'Semantic': f\"{row['Semantic Similarity']:.3f}\",\n",
    "                'ROUGE-1': f\"{row['ROUGE-1 F1']:.3f}\"\n",
    "            })\n",
    "\n",
    "latex_df = pd.DataFrame(latex_data)\n",
    "print(\"LaTeX Table:\")\n",
    "print(latex_df.to_latex(index=False, escape=False))\n",
    "\n",
    "# Save to file\n",
    "latex_df.to_latex('../results/results_table.tex', index=False, escape=False)\n",
    "print(\"\\nTable saved to results/results_table.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This analysis demonstrates the trade-offs between compression ratio and reconstruction quality across different models and masking probabilities. Key findings can be summarized and used for the MSc thesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
